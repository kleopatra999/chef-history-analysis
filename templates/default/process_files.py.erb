import subprocess
import sys
import psycopg2
import re
import json
import yaml
import string

osm2pgsql_bin = '/usr/local/bin/osm2pgsql'
osm2pgsql_style = '<%= node[:history_splitter][:dstdir] + '/default.style' %>'
osmium_tool_bin = '/usr/local/bin/osmium'
years = range(2008, 2016)
filestem = sys.argv[1]
bbox = tuple([float(x) for x in sys.argv[2].split(",")])
user = 'analysis'
queries_file = '<%= node[:history_splitter][:dstdir] + '/queries.yaml' %>'

def run(cmd):
    try:
        subprocess.check_output(cmd, stderr=subprocess.STDOUT, shell=True)
    except subprocess.CalledProcessError, e:
        print>>sys.stderr, "EXCEPTION: %s\nOUTPUT:\n%s" % (str(e), e.output)
        raise e

queries = yaml.load(open(queries_file, 'r'))

results = dict()
bbox = "st_transform(st_setsrid(st_makebox2d(st_makepoint(%f,%f),st_makepoint(%f,%f)),4326),900913)" % bbox
for year in years:
    # creat the database and set it up for import
    safe_name = "%s_%d" % (filestem, year)
    run("dropdb --if-exists %s" % safe_name)
    run("createdb -E UTF-8 -O %s %s" % (user, safe_name))
    conn = psycopg2.connect("dbname=%s" % safe_name)
    cur = conn.cursor()
    cur.execute("create extension postgis")
    cur.execute("create extension hstore")
    cur.close()
    conn.commit()

    # extract the snapshot at new year
    run("rm -f %s.osm.pbf" % safe_name)
    run("%s time-filter -o %s.osm.pbf %s.osh.pbf %d-01-01T00:00:00Z" % (osmium_tool_bin, safe_name, filestem, year))

    # import it into the database
    run("%s -S %s -d %s -G -x -k -K -U %s %s.osm.pbf" % (osm2pgsql_bin, osm2pgsql_style, safe_name, user, safe_name))

    # run queries
    cur = conn.cursor()
    year_results = dict()
    for name, query in queries.iteritems():
        template = string.Template(query)
        cur.execute(template.safe_substitute(geom=("st_intersection(way,%s)" % bbox)))
        if len(cur.description) == 1 and cur.rowcount == 1:
            year_results[name] = cur.fetchone()[0]
        else:
            r = list()
            names = [d[0] for d in cur.description]
            for row in cur.fetchall():
                r.append(dict(zip(names, row)))
            year_results[name] = r

    results[year] = year_results

    # need to close connection before it can be dropped
    conn.close()

    # drop database to reclaim disk space
    run("dropdb --if-exists %s" % safe_name)

with open("%s.json" % filestem, 'w') as fh:
    json.dump(results, fh)
